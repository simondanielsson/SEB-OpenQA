# -- Dataset info --

# Insert path to  , assuming root is the `data/` directory
data_path: <insert path to your squad-formatted labeled dataset>

# -- Pipeline info --

# Name of pipeline as called in `basic.haystack-pipeline.yml`, among for instance
# - basic_ranker_pipeline
# - query_pipeline
# - fef_large_pipeline
# - sparse_query_pipeline
pipeline_name: query_pipeline
do_eval: True
eval_batch: True
batch_size: 16

# -- Evalutation config, activated by do_eval == True --
drop_negative_labels: False
drop_no_answers: False
document_scope: document_id_or_answer
answer_scope: any
# Hyperparameter settings. The nodes must coincide with those found in the
#   chosen pipeline in `basic.haystack-pipeline.yml`.
eval_config:
  params:
    Retriever:
      top_k: 20
      debug: False
    Reader:
      top_k: 1
      debug: False
    Ranker: 
      top_k: 1
      debug: False
    FinalEvidenceFusion: 
      debug: True
  add_isolated_node_eval: True
  sas_model_name_or_path: cross-encoder/stsb-distilroberta-base


# -- Documentstore info --
reset_documentstore: False  # if using FAISS: remember to have to correct DS params in pipeline config
faiss_index_path: 'indices/<name of document store index (faiss)>'
faiss_config_path: 'indices/<name of document store config (json)>'
write_train_documents: True
train_documents_path: <path to training documents, in json or jsonl>
populate_document_store_batch_size: 1000

# -- Preprocessor info --
do_preprocessing: False
preprocessor_params:
  split_by: word
  split_length: 200
  split_overlap: 30
  split_respect_sentence_boundary: False
  clean_empty_lines: True
  clean_whitespace: False