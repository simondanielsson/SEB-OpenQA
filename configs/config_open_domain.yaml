# Config for system evaluation.
# See `basic.haystack-pipeline.yml` for pipeline-specific config.

# -- Dataset info --

# Insert path to  , assuming root is the `data/` directory
data_path: <insert path to your squad-formatted labeled dataset>

# -- Pipeline info --

# Name of pipeline as called in `basic.haystack-pipeline.yml`, among for instance
# - basic_ranker_pipeline
# - query_pipeline
# - fef_large_pipeline
# - sparse_query_pipeline
pipeline_name: in_memory_pipeline
do_eval: True
eval_batch: True
batch_size: 16

# -- Evalutation config, activated by do_eval == True --
drop_negative_labels: False
drop_no_answers: False
document_scope: document_id_or_answer
answer_scope: any
# Hyperparameter settings. The nodes names must coincide with those found in the
#   chosen pipeline in `basic.haystack-pipeline.yml`.
eval_config:
  params:
    <Retriever name>:
      top_k: 1
      debug: False
    <Reader name>:
      top_k: 1
      debug: False
    # Optional:
    #Ranker:
    #  top_k: 1
    #  debug: False
    #FinalEvidenceFusion:
    #  debug: True
  add_isolated_node_eval: True
  # Optional: collect semantic answer similarity metric
  # sas_model_name_or_path: cross-encoder/stsb-distilroberta-base


# -- Documentstore info --
reset_documentstore: True  # if using FAISS: remember to have to correct DS params in pipeline config
faiss_index_path: indices/<name of document store index (faiss)>
faiss_config_path: indices/<name of document store config (json)>
write_train_documents: False
train_documents_path: <path to training documents, in json or jsonl>
populate_document_store_batch_size: 1000

# -- Preprocessor info --
do_preprocessing: False
preprocessor_params:
  split_by: word
  split_length: 200
  split_overlap: 30
  split_respect_sentence_boundary: False
  clean_empty_lines: True
  clean_whitespace: False